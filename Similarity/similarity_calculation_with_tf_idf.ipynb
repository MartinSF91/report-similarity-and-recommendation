{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlparse\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import glob\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', 400)\n",
    "import re\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_query_similarity_with_tf_idf():\n",
    "\n",
    "    migrated_queries = read_in_excel_files(\"../Query Processing/1_migrated_excel_queries/*.xlsx\")\n",
    "    migrated_queries_preprocessed = preprocess_query_df(migrated_queries, \"new\")\n",
    "\n",
    "    new_queries = read_in_excel_files(\"../Query Processing/2_new_excel_queries/*.xlsx\")\n",
    "    new_queries_preprocessed = preprocess_query_df(new_queries, \"new1\")\n",
    "\n",
    "    return calculate_query_similarity(migrated_queries_preprocessed, new_queries_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = calculate_query_similarity_with_tf_idf()\n",
    "res.to_excel(\"./Results/similarity_report_tf_idf.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `read_in_excel_files`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_excel_files(PATH):\n",
    "    try:\n",
    "        excel_data = glob.glob(PATH)\n",
    "\n",
    "        dataframes = [pd.read_excel(data, engine=\"openpyxl\") for data in excel_data]\n",
    "        query_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "        logging.info(f\"Successfully read {len(excel_data)} excel file(s) from {PATH}.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in reading excel files: {e}\")\n",
    "\n",
    "    return query_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `preprocess_query_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_query_df(query_df, QUERY_IDENTIFIER):\n",
    "    \"\"\"\n",
    "    Preprocesses a DataFrame of SQL queries by cleaning and formatting the SQL strings.\n",
    "\n",
    "    Parameters:\n",
    "    query_df (DataFrame): A DataFrame containing SQL queries with a column named 'SQL'.\n",
    "    QUERY_IDENTIFIER (str): A string identifier for the type of queries being processed, used for logging purposes.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: The preprocessed DataFrame with cleaned and formatted SQL queries.\n",
    "\n",
    "    The method performs the following steps:\n",
    "    1. Logs the start of the preprocessing.\n",
    "    2. Drops rows with missing 'SQL' values and fills other missing values with an empty string.\n",
    "    3. Replaces special characters in the 'SQL' column with their ASCII equivalents.\n",
    "    4. Applies several regex patterns to clean and format the SQL queries:\n",
    "        - Removes 'WITH' clauses.\n",
    "        - Strips schema names and table aliases.\n",
    "        - Replaces single quotes with double quotes and removes newline characters.\n",
    "        - Strips comments and reindents the SQL.\n",
    "        - Removes redundant spaces and standardizes alias formatting.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Started {preprocess_query_df.__name__} for {QUERY_IDENTIFIER} queries.\")\n",
    "\n",
    "    query_df = query_df.dropna(subset=[\"SQL\"]).fillna(\"\")\n",
    "\n",
    "    query_df[\"SQL\"] = (query_df[\"SQL\"]\n",
    "                       .str.replace('ê', 'e').str.replace('é', 'e').str.replace('è', 'e').str.replace('à', 'a').str.replace('ç', 'c')\n",
    "                       .str.replace('ô', 'o').str.replace('û', 'u').str.replace('ù', 'u').str.replace('î', 'i').str.replace('ï', 'i')\n",
    "                       .str.replace('â', 'a').str.replace('ä', 'a').str.replace('ö', 'o').str.replace('ü', 'u').str.replace('ÿ', 'y')\n",
    "                       .str.replace('ñ', 'n').str.replace('É', 'E').str.replace('È', 'E').str.replace('À', 'A').str.replace('Ç', 'C')\n",
    "                       .str.replace('Ô', 'O').str.replace('Û', 'U').str.replace('Ù', 'U').str.replace('Î', 'I').str.replace('Ï', 'I')\n",
    "                       .str.replace('Â', 'A').str.replace('Ä', 'A').str.replace('Ö', 'O').str.replace('Ü', 'U').str.replace('Ÿ', 'Y')\n",
    "                       .str.replace('Ñ', 'N')\n",
    "    )\n",
    "\n",
    "    with_pattern = r'WITH\\s+\"\\w+\"\\s+AS\\s*\\(.*?\\)\\s*SELECT'\n",
    "    pattern_2 = r'\"[^\"]*\"\\.'\n",
    "    pattern_3 = r'\\w+\\.'\n",
    "\n",
    "    for index, query in enumerate(query_df[\"SQL\"]):\n",
    "        formatted_query = query.upper()\n",
    "        formatted_query = sqlparse.format(formatted_query, reindent=True, keyword_case='upper', strip_comments=True).strip()\n",
    "        formatted_query = formatted_query.replace(\"'\", '\"').replace(\"\\n\", \" \")\n",
    "        formatted_query = re.sub(with_pattern, 'SELECT', formatted_query, flags=re.DOTALL)\n",
    "        formatted_query = re.sub(pattern_2, '', formatted_query)\n",
    "        formatted_query = re.sub(pattern_3, '', formatted_query)\n",
    "        formatted_query = \" \".join(formatted_query.split())\n",
    "        formatted_query = re.sub(r'\"(\\w+)\" AS \"\\1\"', r'\"\\1\"', formatted_query)\n",
    "        formatted_query = re.sub(r'(\"\\w+\")\\s+\"\\w+\"', r'\\1', formatted_query)\n",
    "\n",
    "        query_df.at[index, 'SQL'] = formatted_query\n",
    "\n",
    "    logging.info(f\"Preprocessing of {QUERY_IDENTIFIER} queries successful.\")\n",
    "\n",
    "    return query_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `calculate_query_similarity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_query_similarity(migrated_queries_preprocessed, new_queries_preprocessed):\n",
    "    \"\"\"\n",
    "    Calculates the similarity between new and migrated SQL queries using TF-IDF vectorization and cosine similarity.\n",
    "\n",
    "    Parameters:\n",
    "    migrated_queries_preprocessed (DataFrame): A DataFrame containing preprocessed migrated SQL queries with columns 'SQL' and 'Product Name'.\n",
    "    new_queries_preprocessed (DataFrame): A DataFrame containing preprocessed new SQL queries with columns 'SQL' and 'Product Name'.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: A DataFrame containing the top 3 most similar migrated queries for each new query, with columns:\n",
    "        - 'new_report_name': Name of the new report.\n",
    "        - 'new_report_name_1': Name of the migrated report.\n",
    "        - 'similarity': Similarity score between the new and migrated report.\n",
    "        - 'new_report_sql': SQL of the new report.\n",
    "        - 'new_report_sql_1': SQL of the migrated report.\n",
    "        - 'row_number': Rank of the similarity score for each new report.\n",
    "\n",
    "    The method performs the following steps:\n",
    "    1. Vectorizes the SQL queries using TF-IDF.\n",
    "    2. Computes the cosine similarity between new and migrated queries.\n",
    "    3. Constructs a similarity matrix and filters out identical report names.\n",
    "    4. Creates a DataFrame of similarity scores and ranks the top 3 most similar migrated queries for each new query.\n",
    "    \"\"\"\n",
    "    similarity_matrix = cosine_similarity(tfidf_new, tfidf_migrated)\n",
    "\n",
    "    similarity = []\n",
    "\n",
    "    for i in range(len(new_queries_preprocessed)):\n",
    "        for j in range(len(migrated_queries_preprocessed)):\n",
    "            similarity.append({\n",
    "                'new_report_name': str(new_queries_preprocessed['Product Name'][i]).strip(),\n",
    "                'migrated_report_name': str(migrated_queries_preprocessed['Product Name'][j]).strip(),\n",
    "                'similarity': similarity_matrix[i][j],\n",
    "                'new_report_sql': str(new_queries_preprocessed['SQL'][i]).strip(),\n",
    "                'migrated_report_sql': str(migrated_queries_preprocessed['SQL'][j]).strip(),\n",
    "            })\n",
    "\n",
    "    similarity = [entry for entry in similarity if entry['new_report_name'] != entry['new_report_name_1']]\n",
    "\n",
    "    similarity_df = pd.DataFrame(similarity).drop_duplicates(subset=[\"new_report_name\", \"migrated_report_name\"]).sort_values(by=['new_report_name', 'similarity'], ascending=[True, False])\n",
    "    similarity_df[\"row_number\"] = similarity_df.groupby(\"new_report_name\").cumcount() + 1\n",
    "\n",
    "    return similarity_df[similarity_df[\"row_number\"] < 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
