{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import ollama\n",
    "import chromadb\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "client = chromadb.Client()\n",
    "collection = client.create_collection(name=\"docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, there is no report containing the column 'VORNAME'. \n",
      "\n",
      "Similarity for Report 2: 45.4%\n",
      "Similarity for Report 1: 41.45%\n",
      "Similarity for Report 3: 38.72%\n"
     ]
    }
   ],
   "source": [
    "client.delete_collection(name=\"docs\")\n",
    "collection = client.create_collection(name=\"docs\")\n",
    "\n",
    "documents = [\n",
    "    \"Report 1 contains columns ['ONHANDQTY','PARTNO','PARTREV', 'VOL_M3']\",\n",
    "    \"Report 2 contains columns ['ARRQTY','BUCODE', 'BUCODECR', 'BUTYPE', 'BUTYPECR', 'DELID']\",\n",
    "    \"Report 3 contains columns ['DELTQTY', 'ITEMNO', 'NETVOL', 'STATDATE', 'STATDATE2']\",\n",
    "]\n",
    "\n",
    "columns = \"VORNAME\"\n",
    "\n",
    "res = main(documents, columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `main`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(documents, columns):\n",
    "\n",
    "    PROMPT = f\"Is there a Report containing Columns '{columns}'? If so, provide Report Name\"\n",
    "\n",
    "    EMBEDDING_MODEL = \"mxbai-embed-large:latest\"\n",
    "    LLM_MODEL = \"gemma2:2b\"\n",
    "\n",
    "    document_embeddings = document_embedding(documents, EMBEDDING_MODEL)\n",
    "\n",
    "    prompt_embeddings = ollama.embeddings(model=EMBEDDING_MODEL, prompt=columns)\n",
    "\n",
    "    retrieval_results = retrieve(prompt_embeddings)\n",
    "\n",
    "    similarity = calculate_similarity(document_embeddings, prompt_embeddings, retrieval_results)\n",
    "\n",
    "    generate_answer(LLM_MODEL, retrieval_results, PROMPT, similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `document_embedding`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_embedding(documents, EMBEDDING_MODEL):\n",
    "    document_embeddings = []\n",
    "\n",
    "    for i, d in enumerate(documents):\n",
    "        response = ollama.embed(model=EMBEDDING_MODEL, input=d)\n",
    "        embeddings = response[\"embeddings\"]\n",
    "        document_embeddings.append(embeddings)\n",
    "        collection.add(ids=[str(i)], embeddings=embeddings, documents=[d])\n",
    "\n",
    "    return document_embeddings,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `retrieve`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(embedded_prompt):\n",
    "    retrieval_results = collection.query(query_embeddings=embedded_prompt[\"embedding\"], n_results=3)\n",
    "    return retrieval_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `calculate_similarity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(document_embeddings, embedded_prompt, retrieval_results):\n",
    "    similarities = []\n",
    "\n",
    "    prompt_vector = np.array(embedded_prompt[\"embedding\"]).reshape(1, -1)\n",
    "    for i in range(len(retrieval_results[\"ids\"][0])):\n",
    "        document_vector = np.array(document_embeddings[0][int(retrieval_results[\"ids\"][0][i])]).reshape(1, -1)\n",
    "        similarities.append(cosine_similarity(document_vector, prompt_vector).flatten()[0])\n",
    "\n",
    "    return similarities\n",
    "\n",
    "# def calculate_similarity(document_embeddings, embedded_prompt, retrieval_results):\n",
    "\n",
    "#     document_vector = np.array(document_embeddings[0][int(retrieval_results[\"ids\"][0][0])]).reshape(1, -1)\n",
    "#     prompt_vector = np.array(embedded_prompt[\"embedding\"]).reshape(1, -1)\n",
    "#     similarity = cosine_similarity(document_vector, prompt_vector).flatten()[0]\n",
    "\n",
    "#     return similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `generate_answer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def generate_answer(LLM_MODEL, retrieval_results, PROMPT, similarity):\n",
    "    output = ollama.generate(\n",
    "        model=LLM_MODEL,\n",
    "        prompt=f\"Using this data: {retrieval_results['documents'][0]}. Respond to this prompt: {PROMPT}\", #[\"documents\"][0][0]\n",
    "    )\n",
    "\n",
    "\n",
    "    print(output[\"response\"])\n",
    "    for i, doc in enumerate(retrieval_results[\"documents\"][0]):\n",
    "        match = re.search(r'Report \\d+', retrieval_results[\"documents\"][0][i])\n",
    "        if match:\n",
    "            print(f\"Similarity for {match.group(0)}: {round(similarity[i] * 100, 2)}%\")\n",
    "        else:\n",
    "            print(f\"Similarity for {retrieval_results[\"documents\"][0][i]}: {round(similarity[i] * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
