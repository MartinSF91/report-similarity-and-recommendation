{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Imports`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import chromadb\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.Client()\n",
    "collection = client.create_collection(name=\"docs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `MAIN Embedding`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Time: 8.19s\n"
     ]
    }
   ],
   "source": [
    "client.delete_collection(name=\"docs\")\n",
    "collection = client.create_collection(name=\"docs\")\n",
    "\n",
    "PATH = \"../Query Processing/4_json_results/migrated_query_data.json\"\n",
    "documents = load_json(PATH)\n",
    "document_embeddings = document_embedding(documents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `MAIN Output`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided data, there is a report named **'YVES INBOUND NOT COMPLETED'** that contains the columns  'ACT_END_DATE' and 'BUA_NO_START'. \n",
      "\n",
      "\n",
      "Let me know if you have any other data requests! \n",
      "\n",
      "Reports with highest Similarity:\n",
      "Similarity for Report Name 'YVES INBOUND NOT COMPLETED': 63.53%\n",
      "Similarity for Report Name 'ADM CHECK': 60.53%\n",
      "Similarity for Report Name 'ACTIVITY FOLLOW UP': 58.68%\n",
      "Runtime: 59.72s.\n"
     ]
    }
   ],
   "source": [
    "desired_columns = [\"ACT_END_DATE, BUA_NO_START\"] # YVES INBOUND NOT COMPLETED\n",
    "# desired_columns = [\"ONHANDQTY, PARTNO\"] # CWIS ASTRO CDC CMR\n",
    "# desired_columns = [\"ECARRNO\"] # MIP 490 INBOUND PALLETS AND TOTAL OH\n",
    "# desired_columns = [\"ASTRO_TRIP_ID\", \"ITEM_ID\"] # YVES STORE ORDERS VOLUME BY DAY\n",
    "# desired_columns = [ # AAYE STOCKAGE\n",
    "#     \"AMOONCR\",\n",
    "#     \"CARRSTAT\",\n",
    "#     \"CARRTYPE\",\n",
    "#     \"DIVCODE\",\n",
    "#     \"ECARRNO\",\n",
    "#     \"FLEXDAYS\",\n",
    "#     \"G08PDATE\",\n",
    "#     \"LDCT\",\n",
    "#     \"LOCKCODE\",\n",
    "#     \"LOTID\",\n",
    "# ]\n",
    "\n",
    "get_output_main(desired_columns, document_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Query Embedding Methods`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `load_json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(PATH):\n",
    "    \"\"\"\n",
    "    Load query data from a JSON file, process it, and return a list of formatted document strings.\n",
    "\n",
    "    Parameters:\n",
    "    PATH (str): The file path to the JSON file containing the query data.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of strings, where each string describes a report and its columns.\n",
    "\n",
    "    Function Workflow:\n",
    "    1. Open the JSON file specified by PATH and load its contents into a dictionary.\n",
    "    2. Initialize two lists: report_names and report_columns.\n",
    "    3. Iterate over the items in the dictionary:\n",
    "        - Append the stripped key to report_names.\n",
    "        - Append the \"columns_cleansed\" value to report_columns.\n",
    "    4. Create a DataFrame with columns \"report_name\" and \"report_columns\" from the lists.\n",
    "    5. Apply the function liste_zu_string to the \"report_columns\" column.\n",
    "    6. Create a new column \"documents\" that combines the report name and columns into a formatted string.\n",
    "    7. Handle any exceptions that occur during file operations or data processing.\n",
    "    8. Return a list of formatted document strings by applying the function zeile_zu_string to the \"documents\" column.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with open(PATH, 'r') as json_file:\n",
    "            query_data = json.load(json_file)\n",
    "\n",
    "        report_names = []\n",
    "        report_columns = []\n",
    "\n",
    "        for key, value in query_data.items():\n",
    "            report_names.append(key.strip())\n",
    "            report_columns.append(value[\"columns_cleansed\"])\n",
    "\n",
    "        df = pd.DataFrame({\"report_name\": report_names, \"report_columns\": report_columns})\n",
    "        df['report_columns'] = df[\"report_columns\"].apply(liste_zu_string)\n",
    "\n",
    "        df[\"documents\"] = \"Report Name \" + \"'\" + df[\"report_name\"]+ \"'\" + \" contains columns: \" + df[\"report_columns\"]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"{e}\")\n",
    "\n",
    "    return df[[\"documents\"]].apply(zeile_zu_string, axis=1).tolist()\n",
    "\n",
    "\n",
    "def liste_zu_string(liste):\n",
    "    return ', '.join(map(str, liste))\n",
    "\n",
    "def zeile_zu_string(row):\n",
    "    return ', '.join(map(str, row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `document_embedding`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_embedding(documents):\n",
    "    \"\"\"\n",
    "    Embed a list of documents using a specified model and store the embeddings in a collection.\n",
    "\n",
    "    Parameters:\n",
    "    documents (list): A list of strings, where each string is a document to be embedded.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of embeddings, where each embedding corresponds to a document in the input list.\n",
    "\n",
    "    Function Workflow:\n",
    "    1. Record the start time of the embedding process.\n",
    "    2. Initialize an empty list to store the document embeddings.\n",
    "    3. Iterate over the documents:\n",
    "        - For each document, generate embeddings using the specified model (\"mxbai-embed-large:latest\").\n",
    "        - Append the generated embeddings to the document_embeddings list.\n",
    "        - Add the embeddings and the corresponding document to a collection with a unique identifier.\n",
    "    4. Record the end time of the embedding process.\n",
    "    5. Calculate the total runtime of the embedding process and print it.\n",
    "    6. Return the list of document embeddings.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    document_embeddings = []\n",
    "\n",
    "    for i, doc in enumerate(documents):\n",
    "        response = ollama.embed(model=\"mxbai-embed-large:latest\", input=doc)\n",
    "        embeddings = response[\"embeddings\"]\n",
    "        document_embeddings.append(embeddings)\n",
    "        collection.add(ids=[str(i)], embeddings=embeddings, documents=[doc])\n",
    "    end = time.time()\n",
    "\n",
    "    runtime = end - start\n",
    "    print(f\"Embedding Time: {runtime:.2f}s\")\n",
    "    return document_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Output Methods`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `get_output_main`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_main(desired_columns, document_embeddings):\n",
    "    \"\"\"\n",
    "    Generate output based on desired columns and document embeddings by retrieving relevant documents and calculating similarity.\n",
    "\n",
    "    Parameters:\n",
    "    desired_columns (list): A list of columns that are desired in the output.\n",
    "    document_embeddings (list): A list of embeddings for the documents to be compared.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "\n",
    "    Function Workflow:\n",
    "    1. Record the start time of the process.\n",
    "    2. Convert the desired columns list into a string format using the `liste_zu_string` function.\n",
    "    3. Generate embeddings for the desired columns using the specified model (\"mxbai-embed-large:latest\").\n",
    "    4. Retrieve relevant documents based on the prompt embeddings.\n",
    "    5. Calculate the similarity between the document embeddings and the prompt embeddings, using the retrieval results.\n",
    "    6. Generate the final output based on the desired columns, retrieval results, and similarity scores.\n",
    "    7. Record the end time of the process.\n",
    "    8. Calculate the total runtime of the process and print it.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "\n",
    "    desired_columns = liste_zu_string(desired_columns)\n",
    "\n",
    "    prompt_embeddings = ollama.embeddings(model=\"mxbai-embed-large:latest\", prompt=desired_columns)\n",
    "\n",
    "    retrieval_results = retrieve_relevant_documents(prompt_embeddings)\n",
    "\n",
    "    similarity = calculate_similarity(document_embeddings, prompt_embeddings, retrieval_results)\n",
    "\n",
    "    generate_output(desired_columns, retrieval_results, similarity)\n",
    "\n",
    "    end = time.time()\n",
    "    runtime = end - start\n",
    "    print(f\"Runtime: {runtime:.2f}s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `retrieve_relevant_documents`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_documents(embedded_prompt):\n",
    "    \"\"\"\n",
    "    Retrieve relevant documents based on the embedded prompt.\n",
    "\n",
    "    Parameters:\n",
    "    embedded_prompt (dict): A dictionary containing the embeddings of the prompt.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of retrieval results, where each result is a relevant document.\n",
    "\n",
    "    Function Workflow:\n",
    "    1. Query the collection using the embeddings from the embedded prompt.\n",
    "    2. Retrieve the top 3 relevant documents based on the query embeddings.\n",
    "    3. Return the retrieval results.\n",
    "    \"\"\"\n",
    "    retrieval_results = collection.query(query_embeddings=embedded_prompt[\"embedding\"], n_results=3)\n",
    "    return retrieval_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `calculate_similarity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(document_embeddings, embedded_prompt, retrieval_results):\n",
    "    \"\"\"\n",
    "    Calculate the cosine similarity between document embeddings and an embedded prompt.\n",
    "\n",
    "    Parameters:\n",
    "    document_embeddings (list): A list of embeddings for the documents to be compared.\n",
    "    embedded_prompt (dict): A dictionary containing the embeddings of the prompt.\n",
    "    retrieval_results (dict): A dictionary containing the retrieval results, including document IDs.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of similarity scores between the embedded prompt and each retrieved document.\n",
    "\n",
    "    Function Workflow:\n",
    "    1. Initialize an empty list to store the similarity scores.\n",
    "    2. Convert the embedded prompt into a NumPy array and reshape it for similarity calculation.\n",
    "    3. Iterate over the retrieved document IDs:\n",
    "        - For each document ID, convert the corresponding document embedding into a NumPy array and reshape it.\n",
    "        - Calculate the cosine similarity between the document embedding and the prompt embedding.\n",
    "        - Append the similarity score to the similarities list.\n",
    "    4. Return the list of similarity scores.\n",
    "    \"\"\"\n",
    "    similarities = []\n",
    "\n",
    "    prompt_vector = np.array(embedded_prompt[\"embedding\"]).reshape(1, -1)\n",
    "    for i in range(len(retrieval_results[\"ids\"][0])):\n",
    "        document_vector = np.array(document_embeddings[int(retrieval_results[\"ids\"][0][i])][0]).reshape(1, -1)\n",
    "        similarities.append(cosine_similarity(document_vector, prompt_vector).flatten()[0])\n",
    "\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `generate_output`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output(desired_columns, retrieval_results, similarity):\n",
    "    \"\"\"\n",
    "    Generate output based on desired columns, retrieval results, and similarity scores.\n",
    "\n",
    "    Parameters:\n",
    "    desired_columns (str): A string representing the columns desired in the document.\n",
    "    retrieval_results (dict): A dictionary containing the retrieval results, including document details.\n",
    "    similarity (list): A list of similarity scores between the embedded prompt and each retrieved document.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "\n",
    "    Function Workflow:\n",
    "    1. Define a prompt asking for a report containing the desired columns.\n",
    "    2. Generate a response using the specified model (\"gemma2:2b\") based on the retrieval results and the prompt.\n",
    "    3. Print the generated response.\n",
    "    4. Print the reports with the highest similarity scores:\n",
    "        - Iterate over the retrieved documents.\n",
    "        - Extract the report name using a regular expression.\n",
    "        - Print the similarity score for each report.\n",
    "    \"\"\"\n",
    "    PROMPT = f\"Please check if there is a report containing the columns '{desired_columns}'. If such a report exists, provide the report name.\"\n",
    "\n",
    "    output = ollama.generate(\n",
    "        model=\"gemma2:2b\",\n",
    "        prompt=f\"Using this data: {retrieval_results[\"documents\"][0][0]}. Respond to this prompt: {PROMPT}\",\n",
    "    )\n",
    "\n",
    "    print(output[\"response\"])\n",
    "    print(\"Reports with highest Similarity:\")\n",
    "    for i, doc in enumerate(retrieval_results[\"documents\"][0]):\n",
    "        match = re.search(r\"Report Name '.*?'\", retrieval_results[\"documents\"][0][i])\n",
    "        if match:\n",
    "            print(f\"Similarity for {match.group(0)}: {round(similarity[i] * 100, 2)}%\")\n",
    "        else:\n",
    "            print(f\"Similarity for {retrieval_results[\"documents\"][0][i]}: {round(similarity[i] * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
